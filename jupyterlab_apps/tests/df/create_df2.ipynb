{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/13 08:05:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Spark session internally creates a sparkContext variable of SparkContext. \n",
    "# You can create multiple SparkSession objects but only one SparkContext per JVM. \n",
    "# In case if you want to create another new SparkContext you should stop existing \n",
    "# Sparkcontext (using stop()) before creating a new one.\n",
    "# Create SparkSession.\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"create_df\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"language\",\"users_count\"]\n",
    "data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using create from rdd\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "\n",
    "df_from_rdd = rdd.toDF()\n",
    "df_from_rdd.printSchema()\n",
    "\n",
    "df_from_rdd = rdd.toDF(columns)\n",
    "df_from_rdd.printSchema()\n",
    "df_from_rdd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using createDataFrame() from SparkSession\n",
    "df_from_data = spark.createDataFrame(rdd).toDF(*columns)\n",
    "df_from_data = spark.createDataFrame(data).toDF(*columns)\n",
    "df_from_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Using createDataFrame() with the Row type\n",
    "row_data = map(lambda x: Row(*x), data) \n",
    "df_from_data = spark.createDataFrame(row_data,columns)\n",
    "df_from_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates Empty RDD\n",
    "emptyRDD = spark.sparkContext.emptyRDD()\n",
    "print(emptyRDD)\n",
    "#Create Schema\n",
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "schema = StructType([\n",
    "  StructField('firstname', StringType(), True),\n",
    "  StructField('middlename', StringType(), True),\n",
    "  StructField('lastname', StringType(), True)\n",
    "  ])\n",
    "#Create empty DataFrame from empty RDD\n",
    "df = spark.createDataFrame(emptyRDD,schema)\n",
    "df.printSchema()\n",
    "#Convert empty RDD to Dataframe\n",
    "df1 = emptyRDD.toDF(schema)\n",
    "df1.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
